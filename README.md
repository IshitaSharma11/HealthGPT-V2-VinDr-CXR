
# ğŸ©º HealthGPT V2: Enhancing Medical AI Fairness & Interpretability with VinDr-CXR

> **Towards Fair and Explainable Medical AI**  
> _Augmenting HealthGPT with Vietnamese Chest X-ray Data (VinDr-CXR)_

![Banner](A_comprehensive_project_overview_of_"HealthGPT_V2:.png)

---

## ğŸ“˜ Overview

HealthGPT V2 enhances the foundational HealthGPT model by integrating **VinDr-CXR**, a large chest X-ray dataset from Vietnam, to improve **fairness**, **clinical interpretability**, and **spatial grounding** of predictions. Targeted for use in **Lower-Middle-Income Countries (LMICs)**, this model addresses geographic bias and improves disease localization using bounding box annotations.

---

## ğŸ§  Key Features

- ğŸ”„ Multi-Task Learning: Presence detection, spatial localization, and diagnosis prediction.
- ğŸ§­ Region Alignment Module: Concept-to-region mapping for explainable outputs.
- ğŸŒ Domain Adaptation: Adversarial learning + histogram matching for cross-region generalization.
- âš–ï¸ Fairness Metrics: Evaluated using Demographic Parity and Equal Opportunity Difference.
- ğŸ§  Interpretability: Grad-CAM & Attention Rollout for radiologist-interpretable insights.
- âš™ï¸ H-LoRA Fine-Tuning: Efficient adaptation using Heterogeneous Low-Rank Adaptation.

---

## ğŸ—‚ Project Structure

```
ğŸ“‚HealthGPT-V2/
â”œâ”€â”€ configs/             # Training and model configs
â”œâ”€â”€ models/              # Vision-language model components
â”œâ”€â”€ scripts/             # Preprocessing, training, and evaluation scripts
â”œâ”€â”€ datasets/            # Data loading and transformation utilities
â”œâ”€â”€ results/             # Outputs, predictions, and metrics
â”œâ”€â”€ README.md            # Project documentation (this file)
```

---

## ğŸ©» Dataset: VinDr-CXR

- 18,000+ annotated chest X-rays from Vietnam
- 14 clinical findings with bounding boxes
- Official dataset: [VinDr-CXR Dataset](https://vindr.ai/datasets/cxr)

---

## âš™ï¸ Pipeline Highlights

### ğŸ§¬ Enhanced Architecture

```text
Input X-ray
    â†“
Image Encoder (Frozen CLIP-ViT)
    â†“                            â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’
Text Encoder (Disease Concepts)         â†“
    â†“                            Bounding Box Head â†’ Location
    â†“                            Answer Head       â†’ Diagnosis
    â†“                            Presence Head     â†’ Normal/Abnormal
```

### ğŸ§ª Multi-Task Loss Function

```python
Loss = L_presence + Î»_bbox * L_bbox + L_answer
```

- **L_presence**: Binary cross-entropy
- **L_bbox**: Generalized IoU loss (for abnormal cases)
- **L_answer**: Multi-class cross-entropy

---

## ğŸš¦ Inference Workflow

1. Load DICOM â†’ Convert to RGB Tensor â†’ CLIP Normalize  
2. Extract Features (Image + Text)
3. Predict:
    - Normal: Return â€œNo Findingâ€
    - Abnormal: Return Disease + Bounding Box
4. Export results as JSON

---

## ğŸ“Š Evaluation Metrics

| Task             | Metric                               |
|------------------|----------------------------------------|
| Classification   | ROC-AUC, F1-score                     |
| Localization     | IoU, mAP, Recall                      |
| Fairness         | Demographic Parity, Equal Opportunity |
| Interpretability | Grad-CAM, Attention Rollout           |

---

## ğŸ’¡ Use Cases

- ğŸ‘©â€âš•ï¸ **Radiologists** â€“ Visualize and verify region-based findings.
- ğŸŒ **Public Health** â€“ Validate fairness across global populations.
- ğŸ‘¨â€ğŸ’» **Engineers** â€“ Build upon a robust and explainable VL-Medical model.

---

## âš ï¸ Known Limitations

- Limited training data usage (<100 GB) due to compute limits
- Geographic data mostly from Vietnam (limited LMIC diversity)
- High GPU demand (A100 preferred)
- 6â€“7 month dataset access approval timeline

---

## ğŸš€ Future Work

- Expand geographic dataset diversity
- Incorporate multilingual medical questions
- Improve model sustainability and efficiency

---

## ğŸ“š References

1. [HealthGPT Paper](https://doi.org/10.48550/arXiv.2502.09838)  
2. [VinDr-CXR Dataset](https://doi.org/10.1038/s41597-022-01498-w)  
3. [LoRA: Low-rank Adaptation](https://arxiv.org/abs/2106.09685)  
4. [DETR Object Detection](https://arxiv.org/abs/2005.12872)  
5. [Bias Metrics](https://doi.org/10.1145/3308558.3313444)

---

## ğŸ”— Repository

> [ğŸ”¬ GitHub: HealthGPT-V2 VinDr-CXR](https://github.com/Salmansaleem007/HealthGPT-V2-VinDr-CXR)
